---
title: 'Blog Post 6 - The Ground Game'
author: Giovanni Salcedo
date: '2022-10-19'
slug: []
categories: []
tags: []
summary: In this post, I will look at voter turnout and how it may be influenced by factors like expert predictions and ad spend. I will also update my model to incorporate turnout and make a prediction for CA-27.
---

*This blog is part of a series for Gov 1347: Election Analytics, a course at [Harvard University](https://www.harvard.edu/) taught by Professor [Ryan D. Enos](http://ryandenos.com/)*.

# Introduction

Last week, we looked at the "air war," where political campaigns fight each other through political advertisements that promote each side and/or attack the other side. Now, we are about to take the war to the ground as we look at how campaigns try to influence voter turnout in their favor.

"Turnout" isn't just about the number or percentage of voters showing up to the polls - it's about *who* shows up and *why*. Campaigns usually invest in on-the-ground operations to do two things:

**1. Mobilize voters:** For a candidate, having voters agree with you is not enough - they need to show up! By getting supporters to stop procrastinating filling out their mail-in ballot or helping them get to the polls on election day, campaigns can tap into their base and increase the number of votes they receive. Ideally, a candidate would want more people from their side to show up than the other side!

**2. Persuade voters:** Besides getting people who already support or lean towards a candidate to actually go vote, campaigns also try to convince people who are on the fence or do not have strong leanings either way to join their side and vote.

# What Can Predict Turnout?

In this post, I wanted to look at two different variables - expert predictions and spending on political ads - and see if they had any sort of relationship to turnout.

For expert predictions, I used data provided from class a few weeks ago that provides average expert ratings for many House districts. For many other districts, there are no ratings, but presumably that is because these districts were solidly in the camp of one party, and experts would likely want to focus on the races that are more competitive. Nevertheless, I included as much data as was available from 2012 to 2020.

For ad spend, I used last week's data, but instead of limiting the data to just the few months before an election, I included all ad spend data available, as some districts did not have ad spend data for the few months before an election.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
## Load packages
library(tidyverse)
library(readr)
library(gtsummary)

## Load datasets with prelim cleaning
# CVAP
cvap_district <- read_csv("~/Documents/R-Projects/election-blog/Labs/Lab 6/cvap_district_2012-2020_clean.csv") %>%
  # Rename geoid
  rename(st_cd_fips = geoid) %>% 
  # Remove unnecessary columns
  select(-...1, -...2)

# Expert predictions
expert_district <- read_csv("~/Documents/R-Projects/election-blog/Labs/Lab 4/District level forecast/expert_rating.csv") %>% 
  # Select relevant columns
  select(year, state, district, avg_rating) %>% 
  # Rename district column
  rename(cd = district)

# Ad spend
ads <- read_csv("~/Documents/R-Projects/election-blog/Labs/Lab 5/ads_issues_2012-2018.csv") %>% 
  # Rename cycle
  rename(year = cycle) %>% 
  # Remove unnecessary column
  select(-...1)

# District voteshares
dist_pv_df <- read_csv("~/Documents/R-Projects/election-blog/Labs/Lab 6/incumb_dist_1948-2020 (3).csv") %>% 
  # Remove unnecessary columns
  select(-...1, -...2)
```

```{r expert turnout}
## Clean district voteshare df
dist_pv_2012_20 <- dist_pv_df %>%
  # Filter for years 2012-2020
  filter(year >= 2012) %>% 
  rename(cd = district_num) %>%
  # Change cd column numbering for single-digit districts
  mutate(cd = if_else(str_starts(cd, "0"), str_sub(cd, 2, -1), cd))
# Change cd column to numeric
dist_pv_2012_20$cd <- as.numeric(dist_pv_2012_20$cd)

## Clean CVAP df
cvap_2012_20 <- cvap_district %>%
  # Filter out 2019 data and District of Columbia data
  filter(year != 2019, state != "District of Columbia")
# Add spaces between state names with multiple words
cvap_2012_20$state <- str_replace(cvap_2012_20$state, "New", "New ")
cvap_2012_20$state <- str_replace(cvap_2012_20$state, "North", "North ")
cvap_2012_20$state <- str_replace(cvap_2012_20$state, "South", "South ")
cvap_2012_20$state <- str_replace(cvap_2012_20$state, "West", "West ")
cvap_2012_20$state <- str_replace(cvap_2012_20$state, "Rhode", "Rhode ")
# Change at large district numbering to 0
cvap_2012_20$cd <- str_replace(cvap_2012_20$cd, "AL", "0")
# Change cd column to numeric
cvap_2012_20$cd <- as.numeric(cvap_2012_20$cd)

## Clean expert predictions df
expert_2012_20 <- expert_district %>%
  # Filter for years 2012-2020
  filter(year >= 2012 & year <= 2020)
# Change at large district numbering to 0
expert_2012_20$cd <- str_replace(expert_2012_20$cd, "AL", "0")
# Change cd column to numeric
expert_2012_20$cd <- as.numeric(expert_2012_20$cd)

## Merge CVAP and voteshare data
cvap_pv_2012_20 <- left_join(dist_pv_2012_20, cvap_2012_20, by = c("year", "state", "cd", "st_cd_fips"))
# Add expert prediction data
expert_turnout_df <- left_join(cvap_pv_2012_20, expert_2012_20, by = c("year", "state", "cd")) %>%
  # Add totalvotes and turnout variables
  mutate(totalvotes = (RepVotes + DemVotes),
         turnout = (totalvotes/cvap))
```

```{r ad turnout, message=FALSE}
## Clean ad data
ad_spend <- ads %>%
  # Calculate total ad spend for each district every year
  group_by(year, state, district) %>%
  summarize(total_cost = sum(est_cost)) %>%
  rename(cd = district) %>%
  # Change at large district numbering to 0 and change cd column numbering for single-digit districts
  mutate(cd = if_else(str_starts(cd, "0"), str_sub(cd, 2, -1), cd),
         cd = if_else(state %in% c("Alaska", "Delaware", "Montana", "North Dakota", "South Dakota", "Vermont", "Wyoming"), "0", cd))
# Change cd column to numeric
ad_spend$cd <- as.numeric(ad_spend$cd)

## Join ad data with CVAP/voteshare data
ad_turnout_df <- left_join(cvap_pv_2012_20, ad_spend, by = c("year", "state", "cd")) %>% 
  # Add totalvotes and turnout variables
  mutate(totalvotes = (RepVotes + DemVotes),
         turnout = (totalvotes/cvap))
```

# Expert Predictions Turnout Model

```{r expert model, warning=FALSE}
## Linear model of average expert predictions
lm_expert_turnout <- lm(turnout ~ avg_rating, expert_turnout_df)
#summary(lm_expert_turnout)
tbl_regression(lm_expert_turnout, intercept = TRUE)

## Plot
ggplot(expert_turnout_df, aes(avg_rating, turnout)) +
  geom_point() +
  geom_smooth(method = "lm", formula = y ~ x, color = "darkorchid") +
  labs(title = "Y = 0.591422 - 0.008581*X",
       subtitle = "P < 0.05, Adjusted R-squared = 0.01379",
       x = "Average expert rating",
       y = "Percent turnout") +
  theme_bw()
```

The avg_rating variable is coded on a scale from 1 to 7, with 1 representing an average expert rating of "Solid Democratic" for a district and 7 representing an average expert rating of "Solid Republican" for a district. The table and plot above suggest that an increase of 1 in rating - a one-unit shift towards Republicans - has just the slightest negative effect on percent turnout in an election. The coefficient is statistically significant, but the adjusted R-squared is only 0.01379, which suggests that this model is not too great at telling us how much average expert ratings can really be predictive of turnout, and since the effect is so small either way, it also doesn't tell us much about how much ground campaigns do anything for turnout.

# Ad Spend Turnout Model

```{r ad model, warning=FALSE}
## Linear model of total ad spend
lm_ad_turnout <- lm(turnout ~ total_cost, ad_turnout_df)
#summary(lm_ad_turnout)
tbl_regression(lm_ad_turnout, intercept = TRUE)

## Plot
ggplot(ad_turnout_df, aes(total_cost, turnout)) +
  geom_point() +
  geom_smooth(method = "lm", formula = y ~ x, color = "green4") +
  labs(title = "Y = 0.47862 + 5.421e-09*X",
       subtitle = "P < 0.001, Adjusted R-squared = 0.02254",
       x = "Total ad spend ($)",
       y = "Percent turnout") +
  theme_bw()
```

On the other hand, ad spend seems to have a different relationship to turnout based on this model. The more that each party spent on ads, the higher turnout seems to go based on the plot. However, most of the points are clustered to the left, so we have more limited data for those much bigger ad spends. In addition, although the adjusted R-squared of 0.02254 is higher than the expert prediction model, it is still very very low, so this model in particular would not be ideal for making predictions. If this model were much more robust and came to a similar conclusion, one could argue that what happens during the air war of political ads drives at least some people to go vote and potentially convinces others to pick a side, especially when tons of money is poured in.

# Updated 2022 Model for CA-27

Like last week, I could not get district-level predictions to work on the aggregate level, but I was able to build a model incorporating turnout, incumbency, and expert predictions to update my forecast for CA-27, the district I am following.

```{r 2022 linear model}
## Incumbency
incumb_pv <- dist_pv_df %>% mutate(incumb = case_when(winner_party == 'R' & RepStatus == 'Incumbent' ~  TRUE,
                              winner_party == 'D' & DemStatus == 'Incumbent' ~ TRUE,
                              winner_party == 'R' & RepStatus == 'Challenger' ~  FALSE,
                              winner_party == 'D' & DemStatus == 'Challenger' ~  FALSE)) %>% 
  rename(cd = district_num) %>%
  # Change cd column numbering for single-digit districts
  mutate(cd = if_else(str_starts(cd, "0"), str_sub(cd, 2, -1), cd))
# Change cd column to numeric
incumb_pv$cd <- as.numeric(incumb_pv$cd)

## Clean expert predictions df
expert_2020 <- expert_district %>%
  # Filter out 2022
  filter(!year == 2022)
# Change at large district numbering to 0
expert_2020$cd <- str_replace(expert_2020$cd, "AL", "0")
# Change cd column to numeric
expert_2020$cd <- as.numeric(expert_2020$cd)

## Merge CVAP and voteshare data for up to 2020
cvap_pv_2020 <- left_join(incumb_pv, cvap_2012_20, by = c("year", "state", "cd", "st_cd_fips"))

## Combine dfs
model_data <- left_join(cvap_pv_2020, expert_2020, by = c("year", "state", "cd")) %>%
  # Add totalvotes and turnout variables
  mutate(totalvotes = (RepVotes + DemVotes),
         turnout = (totalvotes/cvap))

## Linear model
lm_2022 <- lm(DemVotesMajorPercent ~ avg_rating + incumb + turnout, data = model_data)
summary(lm_2022)
```

This model has an adjusted R-squared of 0.7157, which is impressively high. However, only the avg_rating variable is statistically significant, which is not too surprising since better expert ratings for Republicans will likely translate to lower Democratic vote percentages.

```{r 2022 prediction}
## Subset 2022 data
expert_ca <- expert_district %>% 
  filter(year == 2022 & state == "California" & cd == "27") %>% 
  select(avg_rating) %>% 
  as.numeric()

## Subset 2018 data
turnout_ca <- model_data %>% 
  filter(year == 2018 & state == "California" & cd == 25) %>% 
  select(turnout) %>%
  as.numeric()

incumb_ca <- model_data %>% 
  filter(year == 2018 & state == "California" & cd == 25) %>% 
  select(incumb) %>% 
  as.logical()

# CA-27 2022 prediction
predict(lm_2022, data.frame(avg_rating = expert_ca, incumb = incumb_ca,
                           turnout = turnout_ca), interval = "prediction")
```

Above is the predicted Democratic percent voteshare for the district based on this model. Last week, both the models I used suggests Democratic challenger Christy Smith would win just slightly over 50% of the vote, but this model predicts she will win about 49.48% of the vote, which would be an extremely narrow loss. The lower and upper bounds are wide, but unlike last week, they are arguably more realistic possibilities. Nonetheless, I continue to expect this election to be a nail-biter.
